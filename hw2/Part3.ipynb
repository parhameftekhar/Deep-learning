{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uVVeVEgumZLg"
   },
   "source": [
    "# CE-40959: Deep Learning\n",
    "## HW2 - CIFAR-10 Classification (Pytorch)\n",
    "\n",
    "(18 points)\n",
    "\n",
    "### Deadline: 23 Esfand\n",
    "\n",
    "#### Name:\n",
    "#### Student No.:\n",
    "\n",
    "\n",
    "Please review `Pytorch Tutorial` notebook (materials of the TA classes) before coming to this notebook and you can use `pytorch.org` to learn how to use PyTorch classes and commands.\n",
    "\n",
    "In this part you have to implement MLP for Classification of CIFAR-10 dataset. \n",
    "\n",
    "PyTorch provides the elegantly designed modules and classes `torch.nn`, `torch.optim` , `Dataset` , and `DataLoader` to help you create and train neural networks. In this homework you use them for your implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5alOnjtlGfy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WGj-LMuWmx2q"
   },
   "source": [
    "#### 3.1. Load Data:\n",
    "\n",
    "Complete the followed cell for data loading. \n",
    "In this cell you have to normalize, split and shuffle data for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kgv51um_lJiL"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "cifar_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=None)\n",
    "cifar_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=None)\n",
    "\n",
    "trainloader = None\n",
    "validationloader = None\n",
    "testloader = None\n",
    "##################################################################################\n",
    "# TODO: Use 'torchvision.datasets.CIFAR-10' class for loading CIFAR-10 dataset.  #\n",
    "# This dataset has 50000 data for training and 10000 data for test and every     #\n",
    "# data has shape (3*32*32).                                                      #\n",
    "# Also Use 'torchvision.transforms.Compose' for common image transformations     #\n",
    "# such as normalization and use 'torch.utils.data.DataLoader' class that it      #\n",
    "# represents a Python iterable over a dataset and divides data to Batches.       #\n",
    "# Then Split data into 3 part: Train, Validation and Test. Finally,              #\n",
    "# save iterable data in 'trainloader', 'validationloader', 'testloader'.         #\n",
    "##################################################################################\n",
    "batch_size_train = None\n",
    "batch_size_test = None\n",
    "\n",
    "##################################################################################\n",
    "#                               End of your code                                 #\n",
    "##################################################################################\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdLQ8BpxEoZ-"
   },
   "source": [
    "#### 3.2. Load Data Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eaOeLN3klZ9F"
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Run the following code an check the size of each batch   #\n",
    "############################################################\n",
    "examples = enumerate(trainloader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print('The size and type of each batch in ''trainloader'' is:')\n",
    "print(example_data.size())\n",
    "print(type(example_data))\n",
    "examples = enumerate(testloader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print('\\nThe size and type of each batch in ''testloader'' is:')\n",
    "print(example_data.size())\n",
    "print(type(example_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPMpTd230hLY"
   },
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "# Run the following code and see some of the samples in the dataset #\n",
    "#####################################################################\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images:\n",
    "for i in range(4):\n",
    "    img=torchvision.utils.make_grid(images[i])\n",
    "    ###########################################################\n",
    "    #  If you normalize data , here unnormalize them to see   # \n",
    "    #  clear them.                                            #\n",
    "    ###########################################################\n",
    "    m=None\n",
    "    s=None\n",
    "    img = img *s+m    # unnormalize\n",
    "    ###########################################################\n",
    "    #                   End of your code                      #\n",
    "    ###########################################################\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2, 0)))\n",
    "    plt.title(\"Target Labels: {}\".format(classes[labels[i]]))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKpijVi0E1Zm"
   },
   "source": [
    "#### 3.3. Network Design:\n",
    "Design the layer of your network and select proper hyperparameter. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V8nfR7jqxTBO"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "######################################################################\n",
    "# TODO: Use 'torch.nn' module to design your network for CIFAR-10    #\n",
    "# classification. You have to implement the structure of MLP for it. #\n",
    "# In your design you don't have any limitation and you can use       #\n",
    "# Batch-norm layers, Drop-out layers and etc for generalization      #\n",
    "# improvement (if needed). Use classes and modules from 'torch.nn'.  #\n",
    "# In the following code, the 'MLP' class is your MLP network and     #\n",
    "# this class is inherited from nn.Module, so you can benefit         #\n",
    "# properties of the 'nn.Module'.You may complete '__init__()'        #\n",
    "# constructor by some classes like 'nn.ReLU()' or 'nn.Linear()'      #\n",
    "# to use them in the forward pass of your network.                   #\n",
    "######################################################################\n",
    "  \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        return out\n",
    "\n",
    "######################################################################\n",
    "#                          End of your code                          #\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dGyL8c8E-Rb"
   },
   "source": [
    "#### 3.4. Optimization Algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AXuefQ1GB7Ry"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#############################################################################\n",
    "# TODO: Use a Classification Cross-Entropy loss.Then, use 'torch.optim'     #\n",
    "# module to optimize Cross-Entropy loss. You should select a optimization   #\n",
    "# algorithm and its hyperparameters like learning rate.                     #\n",
    "#############################################################################\n",
    "net = MLP()\n",
    "learning_rate = None\n",
    "criterion = None\n",
    "optimizer = None\n",
    "\n",
    "#############################################################################\n",
    "#                             End of your code                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3jL9GEnZFN-z"
   },
   "source": [
    "#### 3.5. Training:\n",
    "You have to tweak `hidden_dim`, `leanirng_rate`, `weight_scale`, `num_epochs` and `reg` and etc to get a validation accuracy above 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJdyD46TZY0t"
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# TODO: Feed the inputs data to the MLP network and   #\n",
    "# optimize Cross-Entropy loss by using target labels. #\n",
    "# Then update weights and biases.                     #\n",
    "#######################################################\n",
    "\n",
    "num_epochs=None\n",
    "num_batchs = len(trainloader)\n",
    "for epoch in range(num_epochs):\n",
    "    total_train=0\n",
    "    correct_train=0\n",
    "    running_loss = 0.0\n",
    "    for batch, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients:\n",
    "        pass\n",
    "\n",
    "        # forward pass:\n",
    "        pass\n",
    "\n",
    "        # backward pass:\n",
    "        pass\n",
    "\n",
    "        # optimization:\n",
    "        pass\n",
    "        #############################################\n",
    "        #           End of your code                #\n",
    "        #############################################\n",
    "        \n",
    "\n",
    "        # Results: \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        total_train += labels.size(0)\n",
    "        _, predicted_train = torch.max(outputs.data, 1)\n",
    "        correct_train += (predicted_train == labels).sum().item()\n",
    "\n",
    "        if batch % (num_batchs/10) == ((num_batchs/10) -1):\n",
    "            print('[Batch %d / %d] loss: %.3f' %\n",
    "                  (batch + 1, num_batchs, running_loss / (num_batchs/10)))\n",
    "            running_loss = 0.0\n",
    "            torch.save(net.state_dict(), './model.pth')\n",
    "            torch.save(optimizer.state_dict(), './optimizer.pth')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in validationloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    val_acc = correct / total\n",
    "    train_acc = correct_train / total_train\n",
    "    print('(Epoch %d / %d) train acc: %.2f%%; val_acc: %.2f%%' % (\n",
    "          epoch+1, num_epochs, 100*train_acc, 100*val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pLES_37SM6_N"
   },
   "source": [
    "#### 3.6. Test: \n",
    "Run the following cell and test your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lw4zW0GPM6cR"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "test_acc = correct / total\n",
    "print('Accuracy of the network on the test images: %2f %%' % (100 * test_acc ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nrnQkpyENTrR"
   },
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
